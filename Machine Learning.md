---
title: Machine Learning
categories: AI
tags: 
  - Machine Learning
toc: true 
---



# 学习库

Numpy 科学计算库

Pandas 数据分析可视化

Matplotlib 数据可视化

Scikit-learn 机器学习库

## 知识点

### 线性代数

#### 矩阵

数组

## 算法

### 监督学习

分类：最终属于1还是0

回归：最终一个具体值

#### 例子1：房价预测（回归）

![image-20210429100557314-1620280617770](http://img.ron.zone/20210527232253.png)

#### 例子2：肿瘤预测（分类）

一个属性

![image-20210429100923353](http://img.ron.zone/20210527232327.png)

两个属性（特征）

![image-20210429101713120](http://img.ron.zone/20210527232314.png)

无穷多特征：向量机

#### 监督学习算法

#####  代价函数

![image-20210429105008588](http://img.ron.zone/20210527232337.png)

<img src="http://img.ron.zone/20210527232346.png" />

![image-20210429105552665](http://img.ron.zone/20210527232354.png)

一个参数的代价函数可以化为一个一元二次函数

两个参数的代价函数可以化为一个二元二次函数

更多参数可以考虑梯度下降的方式

![image-20210429163240652](http://img.ron.zone/20210527232404.png)

梯度下降需要考虑步伐大小，大小学习速率过慢，太大会错过最优解，甚至会导致发散

![image-20210429164519908](http://img.ron.zone/20210527232414.png)

步长α是动态调整的， 

梯度下降只适用于求解线性回归。（为弓形图像）

![image-20210429170959267](http://img.ron.zone/20210527232425.png)

相比计算出代价函数的最小值，梯度下降更适用于数据量较大的训练集

##### 多元梯度下降

![image-20210430164149341](http://img.ron.zone/20210527232437.png)

##### 特征缩放

![image-20210430165959029](http://img.ron.zone/20210527232448.png)

也可以采取减去均值再除以范围

![image-20210430170710002](http://img.ron.zone/20210527232506.png)

特征或多项式回归

直接求解参数的方法

![image-20210430174937134](http://img.ron.zone/20210527232516.png)

### 非监督学习

聚类算法

![image-20210429102250061](http://img.ron.zone/20210527232523.png)